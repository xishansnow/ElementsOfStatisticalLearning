
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>10.14 例子 &#8212; 统计学习精要(中文)</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="10.15 文献笔记" href="Bibliographic-Notes.html" />
    <link rel="prev" title="10.13 解释性" href="10.13-Interpretation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">统计学习精要(中文)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome to your Jupyter Book
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../01-Introduction/1.1-Introduction.html">
   第一章 引言
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.0-Overview.html">
   第二章 监督学习概览
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.1-Introduction.html">
     2.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.2-Variable-Types-and-Terminology.html">
     2.2 变量类型和术语
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.3-Two-Simple-Approaches-to-Prediction.html">
     2.3 两种简单的预测方式：最小二乘和最近邻
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.4-Statistical-Decision-Theory.html">
     2.4 统计判别理论
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.5-Local-Methods-in-High-Dimensions.html">
     2.5 高维问题的局部方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.7-Structured-Regression-Models.html">
     2.7 结构化的回归模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.8-Classes-of-Restricted-Estimators.html">
     2.8 限制性估计的种类
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.9-Model-Selection-and-the-Bias-Variance-Tradeoff.html">
     2.9 模型选择和偏差-方差的权衡
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/Bibliographic-Notes.html">
     2.10 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.0-Overview.html">
   第三章 线性回归模型
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.1-Introduction.html">
     3.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.2-Linear-Regression-Models-and-Least-Squares.html">
     3.2 线性回归模型和最小二乘法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.3-Subset-Selection.html">
     3.3 选择预测变量的子集
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.4-Shrinkage-Methods.html">
     3.4 收缩的方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.5-Methods-Using-Derived-Input-Directions.html">
     3.5 运用派生输入方向的方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.6-A-Comparison-of-the-Selection-and-Shrinkage-Methods.html">
     3.6 讨论：选择和收缩方法的比较
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.7-Multiple-Outcome-Shrinkage-and-Selection.html">
     3.7 多输出的收缩和选择
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.8-More-on-the-Lasso-and-Related-Path-Algorithms.html">
     3.8 Lasso 和相关路径算法的补充
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.9-Computational-Considerations.html">
     3.9 计算上的考虑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/Bibliographic-Notes.html">
     3.10 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.0-Overview.html">
   第四章 线性分类模型
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.1-Introduction.html">
     4.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.2-Linear-Regression-of-an-Indicator-Matrix.html">
     4.2 指示矩阵的线性回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.3-Linear-Discriminant-Analysis.html">
     4.3 线性判别分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.4-Logistic-Regression.html">
     4.4 逻辑斯蒂回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.5-Separating-Hyperplanes.html">
     4.5 分离超平面
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/Bibliographic-Notes.html">
     4.6 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.0-Overview.html">
   第五章 基展开与正则化
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.1-Introduction.html">
     5.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.2-Piecewise-Polynomials-and-Splines.html">
     5.2 分段多项式和样条
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.3-Filtering-and-Feature-Extraction.html">
     5.3 过滤和特征提取
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.4-Smoothing-Splines.html">
     5.4 平滑样条
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.5-Automatic-Selection-of-the-Smoothing-Parameters.html">
     5.5 平滑参数
     <span class="math notranslate nohighlight">
      \(\lambda\)
     </span>
     的自动选择
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.6-Nonparametric-Logistic-Regression.html">
     5.6 非参逻辑斯蒂回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.7-Multidimensional-Splines.html">
     5.7 多维样条
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.8-Regularization-and-Reproducing-Kernel-Hibert-Spaces.html">
     5.8 正则化和再生核希尔伯特空间理论
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.9-Wavelet-Smoothing.html">
     5.9 小波平滑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/Bibliographic-Notes.html">
     5.10 文献笔记
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/Appendix-Computations-for-B-splines.html">
     附录
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.0-Overview.html">
   第六章 核平滑方法
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.1-One-Dimensional-Kernel-Smoothers.html">
     6.1 一维核平滑器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.2-Selecting-the-Width-of-the-Kernel.html">
     6.2 选择核的宽度
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.3-Local-Regression-in-Rp.html">
     6.3
     <span class="math notranslate nohighlight">
      \(p\)
     </span>
     维空间中的局部回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.4-Structured-Local-Regression-Models-in-Rp.html">
     6.4
     <span class="math notranslate nohighlight">
      \(p\)
     </span>
     维空间中的结构化局部回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.5-Local-Likelihood-and-Other-Models.html">
     6.5 局部似然和其他模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.6-Kernel-Density-Estimation-and-Classification.html">
     6.6 核密度估计和分类
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.7-Radial-Basis-Functions-and-Kernels.html">
     6.7 径向基函数和核
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.8-Mixture-Models-for-Density-Estimation-and-Classification.html">
     6.8 混合模型的密度估计和分类
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.9-Computational-Consoderations.html">
     6.9 计算上的考虑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/Bibliographic-Notes.html">
     6.10 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.0-Overview.html">
   第七章 模型评估与选择
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.1-Introduction.html">
     7.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.2-Bias-Variance-and-Model-Complexity.html">
     7.2 偏差、方差和模型复杂度
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.3-The-Bias-Variance-Decomposition.html">
     7.3 偏差-方差分解
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.4-Optimism-of-the-Training-Error-Rate.html">
     7.4 训练误差率的乐观估计
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.5-Estimates-of-In-Sample-Prediction-Error.html">
     7.5 样本内误差的估计
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.6-The-Effective-Number-of-Parameters.html">
     7.6 参数的有效个数
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.7-The-Bayesian-Approach-and-BIC.html">
     7.7 贝叶斯方法和 BIC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.8-Minimum-Description-Length.html">
     7.8 最小描述长度
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.9-Vapnik-Chervonenkis-Dimension.html">
     7.9 VC维
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.10-Cross-Validation.html">
     7.10 交互验证
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.12-Conditional-or-Expected-Test-Error.html">
     7.12 “条件测试误差”还是“测试误差的期望”？
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/Bibliographic-Notes.html">
     7.13 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.0-Overview.html">
   第八章 模型推断与模型平均
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.1-Introduction.html">
     8.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.3-Bayesian-Methods.html">
     8.3 贝叶斯方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.5-The-EM-Algorithm.html">
     8.5
     <code class="docutils literal notranslate">
      <span class="pre">
       EM
      </span>
      <span class="pre">
       算法
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.6-MCMC-for-Sampling-from-the-Posterior.html">
     8.6 从后验分布采样的 MCMC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.7-Bagging.html">
     8.7 Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.8-Model-Averaging-and-Stacking.html">
     8.8 模型平均和堆叠
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.9-Stochastic-Search.html">
     8.9 随机搜索： Bumping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/Bibliographic-Notes.html">
     8.10 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.0-Overview.html">
   第九章 加法模型、树及相关方法
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.1-Generalized-Additive-Models.html">
     9.1 广义可加模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.2-Tree-Based-Methods.html">
     9.2 基于树的方法(CART)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.3-PRIM.html">
     9.3 PRIM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.4-MARS.html">
     9.4 MARS: 多变量自适应回归样条
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.5-Hierarchical-Mixtures-of-Experts.html">
     9.5 专家的分层混合
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.6-Missing-Data.html">
     9.6 缺失数据
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.7-Computational-Considerations.html">
     9.7 计算的考虑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/Bibliographic-Notes.html">
     9.8 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="10.0-Overview.html">
   第十章 提升方法和加法树
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="10.1-Boosting-Methods.html">
     10.1 boosting方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.2-Boosting-Fits-an-Additive-Model.html">
     10.2 Boosting 拟合可加模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.3-Forward-Stagewise-Additive-Modeling.html">
     10.3 向前逐步加法建模
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.4-Exponential-Loss-and-AdaBoost.html">
     10.4 指数损失和AdaBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.5-Why-Exponential-Loss.html">
     10.5 为什么是指数损失？
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.6-Loss-Functions-and-Robustness.html">
     10.6 损失函数和鲁棒性
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.7-Off-the-Shelf-Procedures-for-Data-Mining.html">
     10.7 数据挖掘的现货方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.8-Spam-Data.html">
     10.8 例子: 垃圾邮件
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.9-Boosting-Trees.html">
     10.9 Boosting 树
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.10-Numerical-Optimization-via-Gradient-Boosting.html">
     10.10 Gradient Boosting的数值优化
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.11-Right-Sized-Trees-for-Boosting.html">
     10.11 大小合适的boosting树
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.12-Regularization.html">
     10.12 正则化
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.13-Interpretation.html">
     10.13 解释性
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     10.14 例子
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Bibliographic-Notes.html">
     10.15 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11-Neural-Networks/11.0-Overview.html">
   第十一章 神经网络
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.1-Introduction.html">
     11.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.2-Projection-Pursuit-Regression.html">
     11.2 投影寻踪回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.3-Neural-Networks.html">
     11.3 神经网络
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.4-Fitting-Neural-Networks.html">
     11.4 拟合神经网络
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.5-Some-Issues-in-Training-Neural-Networks.html">
     11.5 训练神经网络的一些问题
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.6-Example-of-Simulated-Data.html">
     11.6 例子：模拟数据
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.7-Example-ZIP-Code-Data.html">
     11.7 例子：邮编数据
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/Bibliographic-Notes.html">
     11.8 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.0-Overview.html">
   第十二章 支持向量机与柔性判别分析
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.1-Introduction.html">
     12.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.2-The-Support-Vector-Classifier.html">
     12.2 支持向量分类器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.3-Support-Vector-Machines-and-Kernels.html">
     12.3 支持向量机和核
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.4-Generalizing-Linear-Discriminant-Analysis.html">
     12.4 广义线性判别分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.5-Flexible-Disciminant-Analysis.html">
     12.5 FDA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.6-Penalized-Discriminant-Analysis.html">
     12.6 惩罚判别分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.7-Mixture-Discriminant-Analysis.html">
     12.7 混合判别分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/Bibliographic-Notes.html">
     12.8 文献笔记
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/Computational-Considerations.html">
     计算上的考虑
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.0-Overview.html">
   第十三章 原型方法与最近邻方法
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.1-Introduction.html">
     13.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.2-Prototype-Methods.html">
     13.2 原型方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.3-k-Nearest-Neighbor-Classifiers.html">
     13.3 k最近邻分类器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.4-Adaptive-Nearest-Neighbor-Methods.html">
     13.4 自适应最近邻方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.5-Computational-Considerations.html">
     13.5 计算上的考虑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/Bibliographic-Notes.html">
     13.6 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../14-Unsupervised-Learning/14.0-Overview.html">
   第十四章 非监督学习
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.1-Introduction.html">
     14.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.2-Association-Rules.html">
     14.2 关联规则
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.3-Cluster-Analysis.html">
     14.3 聚类分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.4-Self-Organizing-Maps.html">
     14.4 自组织图
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.5-Principal-Components-Curves-and-Surfaces.html">
     14.5 主成分，主曲线和主曲面
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.6-Non-negative-Matrix-Factorization.html">
     14.6 非负矩阵分解
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.7-Independent-Component-Analysis-and-Exploratory-Projection-Pursuit.html">
     14.7 独立成分分析和探索投影寻踪
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.8-Multidimensional-Scaling.html">
     14.8 多维缩放
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.9-Nonlinear-Dimension-Reduction-and-Local-Multidimensional-Scaling.html">
     14.9 非线性降维和局部多维缩放
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.10-The-Google-PageRank-Algorithm.html">
     14.10 谷歌的PageRank算法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/Bibliographic-Notes.html">
     14.11 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../15-Random-Forests/15.0-Overview.html">
   第十五章 随机森林
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/15.1-Introduction.html">
     15.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/15.2-Definition-of-Random-Forests.html">
     15.2 随机森林的定义
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/15.3-Details-of-Random-Forests.html">
     15.3 随机森林的细节
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/15.4-Analysis-of-Random-Forests.html">
     15.4 随机森林的分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/Bibliographic-Notes.html">
     15.5 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../16-Ensemble-Learning/16.0-Overview.html">
   第十六章 集成学习
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../16-Ensemble-Learning/16.1-Introduction.html">
     16.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16-Ensemble-Learning/16.2-Boosting-and-Regularization-Paths.html">
     16.2 Boosting 和正则化路径
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16-Ensemble-Learning/16.3-Learning-Ensembles.html">
     16.3 学习集成
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16-Ensemble-Learning/Bibliographic-Notes.html">
     16.4 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../17-Undirected-Graphical-Models/17.0-Overview.html">
   第十七章 马尔科夫随机场
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/17.1-Introduction.html">
     17.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/17.2-Markov-Graphs-and-Their-Properties.html">
     17.2 马尔科夫图及其性质
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/17.3-Undirected-Graphical-Models-for-Continuous-Variables.html">
     17.3 连续变量的无向图模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/17.4-Undirected-Graphical-Models-for-Discrete-Variables.html">
     17.4 离散变量的无向图模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/Bibliographic-Notes.html">
     17.5 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../18-High-Dimensional-Problems/18.0-Overview.html">
   第十八章 高维度问题
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../18-High-Dimensional-Problems/18.1-When-p-is-Much-Bigger-than-N.html">
     18.1 当p远大于N
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18-High-Dimensional-Problems/18.2-Diagonal-Linear-Discriminant-Analysis-and-Nearest-Shrunken-Centroids.html">
     18.2 对角线性判别分析和最近收缩重心
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18-High-Dimensional-Problems/18.3-Linear-Classifiers-with-Quadratic-Regularization.html">
     18.3 二次正则化的线性分类器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18-High-Dimensional-Problems/18.4-Linear-Classifiers-with-L1-Regularization.html">
     18.4
     <span class="math notranslate nohighlight">
      \(L_1\)
     </span>
     正则的线性分类器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18-High-Dimensional-Problems/18.5-Classification-When-Features-are-Unavailable.html">
     18.5 当特征不可用时的分类
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18-High-Dimensional-Problems/18.6-High-Dimensional-Regression.html">
     18.6 高维回归: 有监督的主成分
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18-High-Dimensional-Problems/18.7-Feature-Assessment-and-the-Multiple-Testing-Problem.html">
     18.7 特征评估和多重检验问题
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18-High-Dimensional-Problems/Bioliographic-Notes.html">
     18.8 文献笔记
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/10-Boosting-and-Additive-Trees/10.14-Illustrations.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/xishansnow/ElementsOfStatisticalLearning"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/xishansnow/ElementsOfStatisticalLearning/issues/new?title=Issue%20on%20page%20%2F10-Boosting-and-Additive-Trees/10.14-Illustrations.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   （）加利福利亚住宅
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   （）新西兰鱼
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   （）人口数据
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>10.14 例子</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   （）加利福利亚住宅
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   （）新西兰鱼
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   （）人口数据
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>10.14 例子<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>这一节我们在几个大型数据集上采用合适的损失函数应用 Gradient Boosting 方法。</p>
<div class="section" id="id2">
<h2>（）加利福利亚住宅<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>数据集 (Pace and Barry, 1997)<a class="footnote-reference brackets" href="#id12" id="id3">1</a> 可以在 CMU StatLib 仓库中找到。</p>
<blockquote>
<div><p>note “weiya 注：”
原书作者脚注给出的链接是 <a class="reference external" href="http://lib.stat.cmu.edu">http://lib.stat.cmu.edu</a>，但无法访问，应该是 <a class="reference external" href="http://lib.stat.cmu.edu/datasets/">http://lib.stat.cmu.edu/datasets/ </a>。</p>
</div></blockquote>
<p>数据中包含加利福利亚 20460 个小区（1990 年人口普查块群）的 <strong>聚合数据 (aggregated data)</strong>。响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 是每个小区的房子价值的中位数（单位为 $100,000）。预测变量是 <strong>人口统计数据 (demographics)</strong>，比如收入的中位数 <code class="docutils literal notranslate"><span class="pre">MedInc</span></code>，用房子个数 <code class="docutils literal notranslate"><span class="pre">House</span></code> 表征的房屋密度，以及每个房子平均占用面积 <code class="docutils literal notranslate"><span class="pre">AveOccup</span></code>。另外还有的预测变量是每个校区的位置（经度 <code class="docutils literal notranslate"><span class="pre">longitude</span></code> 和纬度 <code class="docutils literal notranslate"><span class="pre">latitude</span></code>），以及一些反映小区中房子特点的量：房间个数的平均值 <code class="docutils literal notranslate"><span class="pre">AveRooms</span></code> 以及卧室个数的平均值 <code class="docutils literal notranslate"><span class="pre">AveBedrms</span></code>。因此总共有 8 个预测变量，都是数值型的。</p>
<blockquote>
<div><p>note “weiya 注：”
这里书中列出的其实只有 7 个，查阅原数据集，发现漏掉的一个是 <code class="docutils literal notranslate"><span class="pre">housing</span> <span class="pre">median</span> <span class="pre">age</span></code>。当然，其实原数据集本来是有 9 个预测变量，另外一个是 <code class="docutils literal notranslate"><span class="pre">population</span></code>，而且给出了 <code class="docutils literal notranslate"><span class="pre">total</span> <span class="pre">rooms</span></code>, <code class="docutils literal notranslate"><span class="pre">total</span> <span class="pre">bedrooms</span></code>，但没有 <code class="docutils literal notranslate"><span class="pre">AveRooms</span></code> 和 <code class="docutils literal notranslate"><span class="pre">AveBedrms</span></code>，所以这里作者大概是直接取平均数省掉了一个变量 <code class="docutils literal notranslate"><span class="pre">population</span></code>。</p>
</div></blockquote>
<p>我们采用 MART 过程来拟合 Gradient Boosting 模型，其中有 <span class="math notranslate nohighlight">\(J=6\)</span> 个终止结点，学习速率 (10.41) 取 <span class="math notranslate nohighlight">\(\nu=0.1\)</span>，并且采用 Huber 损失来预测数值型响应变量。我们随机将数据集分成训练集 (80%) 和测试集 (20%)。</p>
<p><img alt="" src="../_images/fig10.13.png" /></p>
<p>图 10.13 展示了作为在训练数据和测试数据上迭代次数 <span class="math notranslate nohighlight">\(M\)</span> 的函数的平均绝对误差</p>
<div class="math notranslate nohighlight">
\[
\mathrm{AAE} = \mathbb{E} \vert y-\hat f_M(x)\vert \tag{10.53}
\]</div>
<p>测试误差看起来随着 <span class="math notranslate nohighlight">\(M\)</span> 的增大单调降低，并且在早期迅速下降然后随着迭代增加渐渐变成常值。因此，<span class="math notranslate nohighlight">\(M\)</span> 的具体选择不重要，只要它不要太小。在许多应用中都趋向于是这种形式。收缩策略 (10.41) 趋向于消除过拟合的问题，特别是对于较大的数据集。</p>
<p>800 次迭代之后的 AAE 为 0.31。这个可以跟最优常值预测变量的中值 <span class="math notranslate nohighlight">\(\{y_i\}\)</span> （0.89）进行比较。用更熟悉的相似性的量，这个模型的多相关系数的平方是 <span class="math notranslate nohighlight">\(R^2=0.84\)</span>。Pace and Barry (1997)<a class="footnote-reference brackets" href="#id12" id="id4">1</a> 采用一个很复杂巧妙的空间自回归过程，其中每个小区的预测是基于周围小区的 <strong>房子价值的中位数 (median house values)</strong>，并将其他预测变量看成预测变量得到的。变换后预测 <span class="math notranslate nohighlight">\(\log Y\)</span> 时他们达到 <span class="math notranslate nohighlight">\(R^2=0.85\)</span>。将 <span class="math notranslate nohighlight">\(\log Y\)</span> 看成响应变量，gradient boosting 对应的值为 <span class="math notranslate nohighlight">\(R^2=0.86\)</span>。</p>
<p><img alt="" src="../_images/fig10.14.png" /></p>
<p>图 10.14 展示了每个预测变量的相对变量重要度。意料之中，小区中收入的中位数 (median income) 是最相关的预测变量。经度 (longitude)， 纬度 (latitude)，以及平均占用面积 (occupancy) 大致都有收入一半的重要度，而剩下的则没多大影响了。</p>
<p><img alt="" src="../_images/fig10.15.png" /></p>
<p>图 10.15 展示了单变量在最相关的非位置预测变量上的偏相依性图。注意到这些图并不是严格的光滑。这是采用基于树模型的后果。决策树产生了不连续的分段线性模型 (10.25)。多棵树的和 (10.28) 也继承了这个特点，而且自然地有更多的分段。与本书中讨论的其他方法不一样，这里的结果没有任何光滑约束。任意尖锐 (sharp) 的不连续都可以被建模。这些曲线一般呈现出光滑趋势的事实是因为这估计问题中的响应变量的最好的估计值。通常是这种情形。</p>
<p>每幅图中很轴上的短竖线标记了对应变量分布的 <strong>十分位数 (deciles)</strong>。注意到数据的密度在边处较低，特别是对于较大的值。这导致在这些区域曲线不能很好地确定出来。这些图的竖轴尺度是一样的，因此可以直观地比较不同变量的相对重要度。</p>
<p>房屋价值的中位数在收入的中位数上的偏相依性是单调递增的，在整个数据取值范围内几乎成一条直线。房屋价值大体上随着平均占用面积的增长而单调下降，除了当平均占用率小于 1 的情形。房屋价值的中位数对平均房间数不是单调的。近似在 3 个房间数时有个最小值，并且对于较大和较小的房间数都会增大。</p>
<p>房屋价值的中位数看起来对房屋年龄有很弱的偏相依性，但这个与其重要度排名（图 10.14）不一致。这表明这个弱影响可能掩盖掉了与其他变量间更强的交互影响。</p>
<p><img alt="" src="../_images/fig10.16.png" /></p>
<p>图 10.16 展示了房屋价值在房屋年龄中位数和平均占有率的联合偏相依性。对于平均占有率大于 2 的小区，房屋价值近似与房屋年龄独立，然而对于占有率小于 2 的值，对年龄有很强的相依性。</p>
<p><img alt="" src="../_images/fig10.17.png" /></p>
<p>图 10.17 用带阴影的等高图展示了拟合模型在经度和纬度上的联合偏相依性。很显然在加利福利亚，房屋价值中位数对小区的位置有很强的相依性。注意到图 10.17 不是房屋价值在忽略其他预测变量影响后对位置的影响 (10.49)。和所有偏相依性图一样，它表示了在考虑完其他小区和房屋特征后位置的影响 (10.47)。这可以看成需要对位置支付额外的费用。这个额外的费用在 <strong>太平洋沿岸 (Pacific coast)</strong> 会相对更大，特别是在 <strong>海湾地区 (Bay Area)</strong> 以及 <strong>洛杉矶 - 圣地亚哥 (Los Angeles–San Diego)</strong> 。在加利福利亚的北方，中央山谷，以及东南沙漠地区，位置费用相当地少。</p>
</div>
<div class="section" id="id5">
<h2>（）新西兰鱼<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>植物和动物生态学家采用关于环境变量的回归模型来预测物种是否存在，以及 <strong>多度 (abundance)</strong> 和 <strong>丰度 (richness)</strong>。</p>
<blockquote>
<div><p>note “weiya 注：abundance 和 richness”
参考 <a class="reference external" href="http://blog.sciencenet.cn/home.php?mod=space&amp;uid=502444&amp;do=blog&amp;id=675964">赵斌：森林土壤碳封存：枯枝落叶同根与真菌的较量</a>，文章将 abundance 翻译成“多度”，并且在评论中指出</p>
</div></blockquote>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&gt; abundance 是某一物种在群落内个体数目多少的，理应翻译成多度，而不是丰度。species richness 是指群落中的物种数目，物种数目越多，越丰富多彩，用丰度来翻译很到位，如果翻译成富集，就不知道什么含义了。我相信英语单词采用这两个词本身是没有用错的，只是以前我们在理解这两个词的时候没有足够注意而已。
</pre></div>
</div>
<p>尽管许多年来，简单的线性回归和参数模型很受欢迎，但是最近的文献表明对更复杂的模型越来越感兴趣，比如广义可加模型（<span class="xref myst">9.1 节</span>的 GAM），多元自适应回归样条（<span class="xref myst">9.4 节</span>的 MARS）以及 boosted regression trees (Leathwick et al., 2005<a class="footnote-reference brackets" href="#id13" id="id6">2</a>; Leathwick et al., 2006<a class="footnote-reference brackets" href="#id14" id="id7">3</a>)。这里我们对一种叫做 Black Oreo Dory 的海洋鱼类（在新西兰附近海域发现）的存在性以及多度进行建模。</p>
<p><img alt="" src="../_images/fig10.18.png" /></p>
<p>图 10.18 展示了 17000 个拖网渔船（深水网捕鱼，最大深度为 2km）的位置，并且其中红色点表示其中 2353 个拖网渔船发现了 Black Oreo，通常记录了 100 个物种中的其中一个。对于每个拖网渔船，记录的捕捞量的单位为千克 (kg)。除了捕捉的物种，还测量了每个拖网渔船一系列的环境因素。这些因素包括平均捕捞深度 <code class="docutils literal notranslate"><span class="pre">AvgDepth</span></code>，水温和 <strong>盐度 (salinity)</strong>。因为后两者与深度强相关，Leathwick et al. (2006)<a class="footnote-reference brackets" href="#id14" id="id8">3</a> 导出根据深度调整（通过单独的非参回归）这两个测量值后得到的残差 <code class="docutils literal notranslate"><span class="pre">TempResid</span></code> 和 <code class="docutils literal notranslate"><span class="pre">SalResid</span></code>。<code class="docutils literal notranslate"><span class="pre">SSTGrad</span></code> 是海表面温度的梯度，而 <code class="docutils literal notranslate"><span class="pre">Chla</span></code> 是通过卫星图象测量的生态产量的一个广泛指标。<code class="docutils literal notranslate"><span class="pre">SusPartMatter</span></code> 提供了悬浮颗粒的度量，特别是对于沿海水域，这个量也是基于卫星测量的。</p>
<p>这个分析的目标是估计在一个拖网渔船中发现 Black Oreo 的概率，以及预期的捕捞量，通过考虑拖网渔船的速度以及距离进行标准化，以及渔网的网格大小。作者们采用 logistic 回归来估计这些概率。对于捕捞量，很自然地假设服从 Poisson 分布，并且对平均量的对数进行建模，但是这通常不是很合适，因为有很多 0。尽管有许多特殊的方法，比如 zero-inflated Poisson (Lambert, 1992<a class="footnote-reference brackets" href="#id15" id="id9">4</a>)，他们选择更简单的方式。</p>
<blockquote>
<div><p>note “weiya 注：Zero-inflated Models”
常见的有两种。</p>
</div></blockquote>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Zero-inflated Poisson (ZIP): 
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[    y\sim \pi I(y=0) + (1-\pi)\mathrm{Poisson}(y; \lambda)
    
\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>其中 $\pi$ 是产生额外 0 的概率。

Zero-inflated negative binomial (ZINB):
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[    y\sim \pi I(y=0) + (1-\pi)\mathrm{NB}(y; r, p)
    
\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>其中 $r, p$ 是标准负二项分布的参数。
</pre></div>
</div>
<p>如果 <span class="math notranslate nohighlight">\(Y\)</span> 是（非负）捕捞量，</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}(Y\mid Y&gt;0,X)\cdot \mathrm{Pr}(Y&gt;0\mid X)\tag{10.54}
\]</div>
<p>其中第二项通过 logistic 回归估计，而且第一项可以仅用 2353 个有正捕捞量的拖网渔船来估计。</p>
<p>对于 logistic 回归，作者采用二项偏差损失函数的 Gradient boosted model (GBM)，其中树的深度为 10，并且收缩因子 <span class="math notranslate nohighlight">\(\nu = 0.025\)</span>。对于正捕捞回归，他们采用平方误差损失的 GBM 对 <span class="math notranslate nohighlight">\(\log(Y)\)</span> 进行建模（树的深度同样为 10，但是 <span class="math notranslate nohighlight">\(\nu=0.01\)</span>），并且未记录预测值。两种情形下他们都采用 10 折交互验证来选择项的个数和收缩因子。</p>
<p><img alt="" src="../_images/fig10.19.png" /></p>
<p>图 10.19（左图）展示了 GBM 模型序列对于 10 折 CV 和测试数据的二项偏差的均值，这比 GAM 模型（每一项采用 8 个自由度的光滑样条）的表现有较大程度的改善。右图展示了两个模型的 ROC 曲线（<span class="xref myst">9.2.5 节</span>），用来衡量预测效果。从这点看，效果似乎差不多，不过正如 AUC（曲线下面的面积）表现的那样，GBM 或许略有优势。对于 sensitivity 和 specificity 相等的点，GBM 达到 <span class="math notranslate nohighlight">\(91\%\)</span>，而 GAM 达到 <span class="math notranslate nohighlight">\(90\%\)</span>。</p>
<p><img alt="" src="../_images/fig10.20.png" /></p>
<p>图 10.20 总结了 logistic GBM 拟合中变量的贡献。我们看到存在一个良好定义的深度范围使得能够捕到 Black Oreo，并且在越冷的水中捕捉得会越频繁。我们不会给出定量捕捉模型的细节；重要的变量大部分是一样的。</p>
<p>在这些模型中使用的所有预测变量在很好的地理网格上都可用；事实上，它们是从环境地图集，卫星图象等中导出——更多细节详见 Leathwick et al. (2006)<a class="footnote-reference brackets" href="#id14" id="id10">3</a>。这也意味着预测值可以在网格中进行，并且导入到 GIS 地图系统。</p>
<p><img alt="" src="../_images/fig10.21.png" /></p>
<p>图 10.21 展示了存在性和捕捉量的预测地图，并且都标准化为相同的拖网渔船条件；因为预测变量随着地理位置而连续变化，所以预测值也是一样。</p>
<p>因为 GBM 模型对交互影响建模、以及自动选择变量的能力，以及对离群值和确实数据的鲁棒性，所以 GBM 模型在这个数据丰富且充满热情的社区中迅速普及。</p>
</div>
<div class="section" id="id11">
<h2>（）人口数据<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p>这一节我们用 MART 举例说明 Gradient Boosting 在多类别分类问题中的应用。数据来自由  San Francisco Bay Area 的超市顾客填写的 9243 份问卷 (Impact Resources, Inc., Columbus, OH)。这些问题涉及 14 个人口统计量。在这个例子中，目标是将其他 13 个变量看成预测变量来预测职业，并且因此找出区分不同职业类的人口统计量。我们随机将数据分成训练集 (80%) 和测试集 (20%)，并且采用 <span class="math notranslate nohighlight">\(J=6\)</span> 个结点的树，且学习速率为 <span class="math notranslate nohighlight">\(\nu = 0.1\)</span>。</p>
<p><img alt="" src="../_images/fig10.22.png" /></p>
<p>图 10.22 展示了 <span class="math notranslate nohighlight">\(K=9\)</span> 个职业类以及它们对应的误差率。总体误差率为 42.5%，这可以与 69% 的 <strong>零分布误差率 (null rate)</strong> （预测最多的类 <code class="docutils literal notranslate"><span class="pre">Prof/Man</span></code> (Professional/Managerial)）。预测效果最好的四个类别似乎是  <code class="docutils literal notranslate"><span class="pre">Retired</span></code>，<code class="docutils literal notranslate"><span class="pre">Student</span></code>，<code class="docutils literal notranslate"><span class="pre">Prof/Man</span></code>，和 <code class="docutils literal notranslate"><span class="pre">Homemaker</span></code>。</p>
<p><img alt="" src="../_images/fig10.23.png" /></p>
<p>图 10.23 展示了对所有类别平均后的相对预测变量重要度 (10.46)。</p>
<p><img alt="" src="../_images/fig10.24.png" /></p>
<p>图 10.24 展示了四个最优预测类别的单个重要度分布 (10.45)。可以看到对于每个单独的类其最重要的预测变量通常都是不一样的。一个例外是 <code class="docutils literal notranslate"><span class="pre">age</span></code>，在预测 <code class="docutils literal notranslate"><span class="pre">Retired</span></code>，<code class="docutils literal notranslate"><span class="pre">Student</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Prof/Man</span></code> 时，它的重要度都是排名前三的。</p>
<p><img alt="" src="../_images/fig10.25.png" /></p>
<p>图 10.25 展示了 <code class="docutils literal notranslate"><span class="pre">age</span></code> 对这三个类别的对数几率 (10.52)的偏相依性。横坐标的值是相应等距排列的年龄区间的有序编号。可以看到再考虑完其他变量的贡献度后，对于年龄较大者，退休的几率很高，与之相反的是学生。对于中年人来说，成为专业人才/管理人才 (professional/managerial) 的几率最高。这些结果当然是意料之中的。他们说明了观察单独地观察每一类的偏独立性能够得出合理的结果。</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id12"><span class="brackets">1</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Pace, R. K. and Barry, R. (1997). Sparse spatial autoregressions, Statistics and Probability Letters 33: 291–297.</p>
</dd>
<dt class="label" id="id13"><span class="brackets"><a class="fn-backref" href="#id6">2</a></span></dt>
<dd><p>Leathwick, J., Rowe, D., Richardson, J., Elith, J. and Hastie, T. (2005). Using multivariate adaptive regression splines to predict the distributions of New Zealand’s freshwater diadromous fish, Freshwater Biology 50: 2034–2051.</p>
</dd>
<dt class="label" id="id14"><span class="brackets">3</span><span class="fn-backref">(<a href="#id7">1</a>,<a href="#id8">2</a>,<a href="#id10">3</a>)</span></dt>
<dd><p>Leathwick, J., Elith, J., Francis, M., Hastie, T. and Taylor, P. (2006). Variation in demersal fish species richness in the oceans surrounding new zealand: an analysis using boosted regression trees, Marine Ecology Progress Series 77: 802–813.</p>
</dd>
<dt class="label" id="id15"><span class="brackets"><a class="fn-backref" href="#id9">4</a></span></dt>
<dd><p>Lambert, D. (1992). Zero-inflated Poisson regression, with an application to defects in manufacturing, Technometrics 34(1): 1–14.</p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./10-Boosting-and-Additive-Trees"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="10.13-Interpretation.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">10.13 解释性</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Bibliographic-Notes.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">10.15 文献笔记</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Trevor Hastie and Robert Tibshirani and Jerome Friedman<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>