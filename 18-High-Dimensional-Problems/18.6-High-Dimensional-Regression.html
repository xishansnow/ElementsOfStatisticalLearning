
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>18.6 高维回归: 有监督的主成分 &#8212; 统计学习精要(中文)</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="18.7 特征评估和多重检验问题" href="18.7-Feature-Assessment-and-the-Multiple-Testing-Problem.html" />
    <link rel="prev" title="18.5 当特征不可用时的分类" href="18.5-Classification-When-Features-are-Unavailable.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">统计学习精要(中文)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome to your Jupyter Book
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../01-Introduction/1.1-Introduction.html">
   第一章 引言
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.0-Overview.html">
   第二章 监督学习概览
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.1-Introduction.html">
     2.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.2-Variable-Types-and-Terminology.html">
     2.2 变量类型和术语
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.3-Two-Simple-Approaches-to-Prediction.html">
     2.3 两种简单的预测方式：最小二乘和最近邻
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.4-Statistical-Decision-Theory.html">
     2.4 统计判别理论
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.5-Local-Methods-in-High-Dimensions.html">
     2.5 高维问题的局部方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.7-Structured-Regression-Models.html">
     2.7 结构化的回归模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.8-Classes-of-Restricted-Estimators.html">
     2.8 限制性估计的种类
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/2.9-Model-Selection-and-the-Bias-Variance-Tradeoff.html">
     2.9 模型选择和偏差-方差的权衡
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-Overview-of-Supervised-Learning/Bibliographic-Notes.html">
     2.10 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.0-Overview.html">
   第三章 线性回归模型
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.1-Introduction.html">
     3.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.2-Linear-Regression-Models-and-Least-Squares.html">
     3.2 线性回归模型和最小二乘法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.3-Subset-Selection.html">
     3.3 选择预测变量的子集
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.4-Shrinkage-Methods.html">
     3.4 收缩的方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.5-Methods-Using-Derived-Input-Directions.html">
     3.5 运用派生输入方向的方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.6-A-Comparison-of-the-Selection-and-Shrinkage-Methods.html">
     3.6 讨论：选择和收缩方法的比较
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.7-Multiple-Outcome-Shrinkage-and-Selection.html">
     3.7 多输出的收缩和选择
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.8-More-on-the-Lasso-and-Related-Path-Algorithms.html">
     3.8 Lasso 和相关路径算法的补充
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/3.9-Computational-Considerations.html">
     3.9 计算上的考虑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-Linear-Methods-for-Regression/Bibliographic-Notes.html">
     3.10 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.0-Overview.html">
   第四章 线性分类模型
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.1-Introduction.html">
     4.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.2-Linear-Regression-of-an-Indicator-Matrix.html">
     4.2 指示矩阵的线性回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.3-Linear-Discriminant-Analysis.html">
     4.3 线性判别分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.4-Logistic-Regression.html">
     4.4 逻辑斯蒂回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/4.5-Separating-Hyperplanes.html">
     4.5 分离超平面
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-Linear-Methods-for-Classification/Bibliographic-Notes.html">
     4.6 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.0-Overview.html">
   第五章 基展开与正则化
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.1-Introduction.html">
     5.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.2-Piecewise-Polynomials-and-Splines.html">
     5.2 分段多项式和样条
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.3-Filtering-and-Feature-Extraction.html">
     5.3 过滤和特征提取
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.4-Smoothing-Splines.html">
     5.4 平滑样条
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.5-Automatic-Selection-of-the-Smoothing-Parameters.html">
     5.5 平滑参数
     <span class="math notranslate nohighlight">
      \(\lambda\)
     </span>
     的自动选择
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.6-Nonparametric-Logistic-Regression.html">
     5.6 非参逻辑斯蒂回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.7-Multidimensional-Splines.html">
     5.7 多维样条
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.8-Regularization-and-Reproducing-Kernel-Hibert-Spaces.html">
     5.8 正则化和再生核希尔伯特空间理论
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/5.9-Wavelet-Smoothing.html">
     5.9 小波平滑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/Bibliographic-Notes.html">
     5.10 文献笔记
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-Basis-Expansions-and-Regularization/Appendix-Computations-for-B-splines.html">
     附录
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.0-Overview.html">
   第六章 核平滑方法
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.1-One-Dimensional-Kernel-Smoothers.html">
     6.1 一维核平滑器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.2-Selecting-the-Width-of-the-Kernel.html">
     6.2 选择核的宽度
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.3-Local-Regression-in-Rp.html">
     6.3
     <span class="math notranslate nohighlight">
      \(p\)
     </span>
     维空间中的局部回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.4-Structured-Local-Regression-Models-in-Rp.html">
     6.4
     <span class="math notranslate nohighlight">
      \(p\)
     </span>
     维空间中的结构化局部回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.5-Local-Likelihood-and-Other-Models.html">
     6.5 局部似然和其他模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.6-Kernel-Density-Estimation-and-Classification.html">
     6.6 核密度估计和分类
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.7-Radial-Basis-Functions-and-Kernels.html">
     6.7 径向基函数和核
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.8-Mixture-Models-for-Density-Estimation-and-Classification.html">
     6.8 混合模型的密度估计和分类
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/6.9-Computational-Consoderations.html">
     6.9 计算上的考虑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-Kernel-Smoothing-Methods/Bibliographic-Notes.html">
     6.10 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.0-Overview.html">
   第七章 模型评估与选择
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.1-Introduction.html">
     7.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.2-Bias-Variance-and-Model-Complexity.html">
     7.2 偏差、方差和模型复杂度
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.3-The-Bias-Variance-Decomposition.html">
     7.3 偏差-方差分解
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.4-Optimism-of-the-Training-Error-Rate.html">
     7.4 训练误差率的乐观估计
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.5-Estimates-of-In-Sample-Prediction-Error.html">
     7.5 样本内误差的估计
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.6-The-Effective-Number-of-Parameters.html">
     7.6 参数的有效个数
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.7-The-Bayesian-Approach-and-BIC.html">
     7.7 贝叶斯方法和 BIC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.8-Minimum-Description-Length.html">
     7.8 最小描述长度
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.9-Vapnik-Chervonenkis-Dimension.html">
     7.9 VC维
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.10-Cross-Validation.html">
     7.10 交叉验证
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/7.12-Conditional-or-Expected-Test-Error.html">
     7.12 “条件测试误差”还是“测试误差的期望”？
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-Model-Assessment-and-Selection/Bibliographic-Notes.html">
     7.13 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.0-Overview.html">
   第八章 模型推断与模型平均
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.1-Introduction.html">
     8.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.3-Bayesian-Methods.html">
     8.3 贝叶斯方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.5-The-EM-Algorithm.html">
     8.5
     <code class="docutils literal notranslate">
      <span class="pre">
       EM
      </span>
      <span class="pre">
       算法
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.6-MCMC-for-Sampling-from-the-Posterior.html">
     8.6 从后验分布采样的 MCMC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.7-Bagging.html">
     8.7 Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.8-Model-Averaging-and-Stacking.html">
     8.8 模型平均和堆叠
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/8.9-Stochastic-Search.html">
     8.9 随机搜索： Bumping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-Model-Inference-and-Averaging/Bibliographic-Notes.html">
     8.10 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.0-Overview.html">
   第九章 加法模型、树及相关方法
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.1-Generalized-Additive-Models.html">
     9.1 广义可加模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.2-Tree-Based-Methods.html">
     9.2 基于树的方法(CART)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.3-PRIM.html">
     9.3 PRIM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.4-MARS.html">
     9.4 MARS: 多变量自适应回归样条
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.5-Hierarchical-Mixtures-of-Experts.html">
     9.5 专家的分层混合
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.6-Missing-Data.html">
     9.6 缺失数据
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/9.7-Computational-Considerations.html">
     9.7 计算的考虑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-Additive-Models-Trees-and-Related-Methods/Bibliographic-Notes.html">
     9.8 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.0-Overview.html">
   第十章 提升方法和加法树
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.1-Boosting-Methods.html">
     10.1 boosting方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.2-Boosting-Fits-an-Additive-Model.html">
     10.2 Boosting 拟合可加模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.3-Forward-Stagewise-Additive-Modeling.html">
     10.3 向前逐步加法建模
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.4-Exponential-Loss-and-AdaBoost.html">
     10.4 指数损失和AdaBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.5-Why-Exponential-Loss.html">
     10.5 为什么是指数损失？
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.6-Loss-Functions-and-Robustness.html">
     10.6 损失函数和鲁棒性
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.7-Off-the-Shelf-Procedures-for-Data-Mining.html">
     10.7 数据挖掘的现货方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.8-Spam-Data.html">
     10.8 例子: 垃圾邮件
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.9-Boosting-Trees.html">
     10.9 Boosting 树
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.10-Numerical-Optimization-via-Gradient-Boosting.html">
     10.10 Gradient Boosting的数值优化
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.11-Right-Sized-Trees-for-Boosting.html">
     10.11 大小合适的boosting树
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.12-Regularization.html">
     10.12 正则化
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.13-Interpretation.html">
     10.13 解释性
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/10.14-Illustrations.html">
     10.14 例子
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-Boosting-and-Additive-Trees/Bibliographic-Notes.html">
     10.15 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11-Neural-Networks/11.0-Overview.html">
   第十一章 神经网络
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.1-Introduction.html">
     11.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.2-Projection-Pursuit-Regression.html">
     11.2 投影寻踪回归
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.3-Neural-Networks.html">
     11.3 神经网络
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.4-Fitting-Neural-Networks.html">
     11.4 拟合神经网络
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.5-Some-Issues-in-Training-Neural-Networks.html">
     11.5 训练神经网络的一些问题
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.6-Example-of-Simulated-Data.html">
     11.6 例子：模拟数据
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/11.7-Example-ZIP-Code-Data.html">
     11.7 例子：邮编数据
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-Neural-Networks/Bibliographic-Notes.html">
     11.8 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.0-Overview.html">
   第十二章 支持向量机与柔性判别分析
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.1-Introduction.html">
     12.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.2-The-Support-Vector-Classifier.html">
     12.2 支持向量分类器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.3-Support-Vector-Machines-and-Kernels.html">
     12.3 支持向量机和核
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.4-Generalizing-Linear-Discriminant-Analysis.html">
     12.4 广义线性判别分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.5-Flexible-Disciminant-Analysis.html">
     12.5 FDA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.6-Penalized-Discriminant-Analysis.html">
     12.6 惩罚判别分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/12.7-Mixture-Discriminant-Analysis.html">
     12.7 混合判别分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/Bibliographic-Notes.html">
     12.8 文献笔记
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-Support-Vector-Machines-and-Flexible-Discriminants/Computational-Considerations.html">
     计算上的考虑
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.0-Overview.html">
   第十三章 原型方法与最近邻方法
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.1-Introduction.html">
     13.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.2-Prototype-Methods.html">
     13.2 原型方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.3-k-Nearest-Neighbor-Classifiers.html">
     13.3 k最近邻分类器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.4-Adaptive-Nearest-Neighbor-Methods.html">
     13.4 自适应最近邻方法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/13.5-Computational-Considerations.html">
     13.5 计算上的考虑
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-Prototype-Methods-and-Nearest-Neighbors/Bibliographic-Notes.html">
     13.6 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../14-Unsupervised-Learning/14.0-Overview.html">
   第十四章 非监督学习
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.1-Introduction.html">
     14.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.2-Association-Rules.html">
     14.2 关联规则
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.3-Cluster-Analysis.html">
     14.3 聚类分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.4-Self-Organizing-Maps.html">
     14.4 自组织图
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.5-Principal-Components-Curves-and-Surfaces.html">
     14.5 主成分，主曲线和主曲面
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.6-Non-negative-Matrix-Factorization.html">
     14.6 非负矩阵分解
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.7-Independent-Component-Analysis-and-Exploratory-Projection-Pursuit.html">
     14.7 独立成分分析和探索投影寻踪
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.8-Multidimensional-Scaling.html">
     14.8 多维缩放
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.9-Nonlinear-Dimension-Reduction-and-Local-Multidimensional-Scaling.html">
     14.9 非线性降维和局部多维缩放
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/14.10-The-Google-PageRank-Algorithm.html">
     14.10 谷歌的PageRank算法
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-Unsupervised-Learning/Bibliographic-Notes.html">
     14.11 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../15-Random-Forests/15.0-Overview.html">
   第十五章 随机森林
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/15.1-Introduction.html">
     15.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/15.2-Definition-of-Random-Forests.html">
     15.2 随机森林的定义
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/15.3-Details-of-Random-Forests.html">
     15.3 随机森林的细节
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/15.4-Analysis-of-Random-Forests.html">
     15.4 随机森林的分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-Random-Forests/Bibliographic-Notes.html">
     15.5 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../16-Ensemble-Learning/16.0-Overview.html">
   第十六章 集成学习
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../16-Ensemble-Learning/16.1-Introduction.html">
     16.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16-Ensemble-Learning/16.2-Boosting-and-Regularization-Paths.html">
     16.2 Boosting 和正则化路径
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16-Ensemble-Learning/16.3-Learning-Ensembles.html">
     16.3 学习集成
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16-Ensemble-Learning/Bibliographic-Notes.html">
     16.4 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../17-Undirected-Graphical-Models/17.0-Overview.html">
   第十七章 马尔科夫随机场
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/17.1-Introduction.html">
     17.1 导言
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/17.2-Markov-Graphs-and-Their-Properties.html">
     17.2 马尔科夫图及其性质
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/17.3-Undirected-Graphical-Models-for-Continuous-Variables.html">
     17.3 连续变量的无向图模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/17.4-Undirected-Graphical-Models-for-Discrete-Variables.html">
     17.4 离散变量的无向图模型
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-Undirected-Graphical-Models/Bibliographic-Notes.html">
     17.5 文献笔记
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="18.0-Overview.html">
   第十八章 高维度问题
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="18.1-When-p-is-Much-Bigger-than-N.html">
     18.1 当p远大于N
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18.2-Diagonal-Linear-Discriminant-Analysis-and-Nearest-Shrunken-Centroids.html">
     18.2 对角线性判别分析和最近收缩重心
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18.3-Linear-Classifiers-with-Quadratic-Regularization.html">
     18.3 二次正则化的线性分类器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18.4-Linear-Classifiers-with-L1-Regularization.html">
     18.4
     <span class="math notranslate nohighlight">
      \(L_1\)
     </span>
     正则的线性分类器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18.5-Classification-When-Features-are-Unavailable.html">
     18.5 当特征不可用时的分类
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     18.6 高维回归: 有监督的主成分
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18.7-Feature-Assessment-and-the-Multiple-Testing-Problem.html">
     18.7 特征评估和多重检验问题
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Bioliographic-Notes.html">
     18.8 文献笔记
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/18-High-Dimensional-Problems/18.6-High-Dimensional-Regression.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/xishansnow/ElementsOfStatisticalLearning"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/xishansnow/ElementsOfStatisticalLearning/issues/new?title=Issue%20on%20page%20%2F18-High-Dimensional-Problems/18.6-High-Dimensional-Regression.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   （）与潜变量模型的联系
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   （）与偏最小二乘的联系
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id14">
   （）特征选择的预处理
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>18.6 高维回归: 有监督的主成分</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   （）与潜变量模型的联系
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   （）与偏最小二乘的联系
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id14">
   （）特征选择的预处理
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>18.6 高维回归: 有监督的主成分<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>这一节中我们将要描述一种在 <span class="math notranslate nohighlight">\(p &gt;&gt; N\)</span> 情形下特别有用的回归和广义回归的简单方法。我们用另外一个微阵列数据的例子来解释这一方法。 数据取自 Rosenwald et al. (2002)<a class="footnote-reference brackets" href="#id17" id="id2">1</a>，其中包含 240 个患有 DLBCL 的病人，有 7399 个基因表达水平的测量值。输出变量为生存时间，取值为 “observed” 或者 “right censored”。我们将样本随机分成大小为 160 的训练集和大小为 80 的测试集。</p>
<p>尽管有监督的主成分对线性回归很有用，但是它最有趣的应用也许是在生存分析中，这也是这个例子所要关注的地方。</p>
<!--
> note "censored survival data"
    个人理解是, 数据中无对应的记录值, 也就是只有部分个体有*生存时间*的记录值, 而其他个体没有记录值.[NEED VERIFIED!!]

-->
<p>我们还没有在这本书中讨论 censored survival 数据的回归问题；它表示了回归的一般形式，输出变量（生存时间）只对一部分个体有观测。举个例子我们实施一项持续 365 天的医学研究，为了简便起见，所有的项目在一天完成。 我们可能会观测到研究开始后有个体200天后就死亡，但也有个体研究结束后还活着。这个个体则称为365天“right censored”。我们仅仅知道他/她至少活了365天。 尽管我们并不知道过了多久该个体会死去, 但“censored”观察值仍然很有意义。 图 18.11 诠释了这一意义。图 18.12 显示了对测试集中的 80个病人应用 Kaplan–Meier 方法估计得到的生存曲线。关于 Kaplan–Meier 方法的描述可以参见 Kalbfleisch and Prentice(1980)<a class="footnote-reference brackets" href="#id18" id="id3">2</a> 中的例子。</p>
<p><img alt="" src="../_images/fig18.11.png" /></p>
<p><img alt="" src="../_images/fig18.12.png" /></p>
<p>在这个例子中我们的目标是寻找可以预测一组独立病人个体的生存时间的特征（基因）集合。这个可以作为一个<strong>预后</strong>指示变量来帮助选择治疗方案, 或者帮助理解这个疾病的生理基础。</p>
<blockquote>
<div><p>note “预后(prognostic)”
预后是指预测疾病的可能病程和结局。它既包括判断疾病的特定后果（如康复，某种症状、体征和并发症等其它异常的出现或消失及死亡）；也包括提供时间线索，如预测某段时间内发生某种结局的可能性。由于预后是一种可能性，主要指病人群体而不是个人。从疾病演进过程的角度划分，预后的量度有缓解率、复发率、病残率等；从疾病终极状态的角度划分，预后的量度有治愈率、生存率、病死率等。 (refer to <a class="reference external" href="http://www.bing.com">www.bing.com</a>)</p>
</div></blockquote>
<p>有监督的主成分的潜在概念模型如图 18.13 所示。</p>
<p><img alt="" src="../_images/fig18.13.png" /></p>
<p>我们想象存在两种类型的细胞，拥有好细胞的病人平均会活得久一些。然而，两者之间存在相当大部分的重叠。我们可能将存活时间作为细胞类型的有噪声的代理变量 (“noisy surrogate”)。全监督方法会赋予那些与生存越有关的基因更多的权重。这些基因与细胞类型部分相关（但不是完全）。换种方式，如果我们能够发现病人潜在的细胞类型，它经常受到通路中相当多的基因一起作用的影响，或许在预测病人的生存方面会取得更好的结果。</p>
<p>尽管图 18.13 中的细胞类型是离散的，但想象其为连续的是有帮助的，将它定义为特征的某些线性组合。我们将会把细胞类型作为连续值来估计，接着为了展示和解释的需要进行离散化。</p>
<p>我们应该怎样寻找这个定义了潜在细胞类型的线性组合呢? <span class="xref myst">第 14.5 节</span>的主成分分析是一个用来发现数据集中表现出大方差的特征的线性组合。但是我们这里需要寻找的是高方差<strong>以及</strong>与响应变量有显著相关性的线性组合。图 18.14 的右下图显示了在这个例子中应用标准的主成分的结果；第一主成分与生存时间的相关性并不是很高。</p>
<p>因此我们想要主成分分析寻找到与输出有高相关的特征的线性组合。为了实现这一点，我们限制在那些本身就与输出变量存在高相关性的变量上。这已经总结在了算法 18.1 中，并且在图 18.14 中做了解释.</p>
<p><img alt="" src="../_images/fig18.14.png" /></p>
<p><img alt="" src="../_images/alg18.1.png" /></p>
<p>算法中第 (1) 和第 (2b) 步的细节取决于输出变量的类型。对于标准的回归问题，我们在步骤 (1) 中采用单变量的线性最小二乘系数，在第 (2b) 步采用线性的最小二乘模型。对于生存分析问题, 广泛使用 <strong>Cox 的比例风险回归 (Cox’s proportional hazards regression)</strong>；因此这里在第 (1) 步，我们采用得分检验，在第 (2b) 步中采用多变量 Cox 模型。具体细节对于理解这一基本方法不重要；它们可以在 Bair et al. (2006)<a class="footnote-reference brackets" href="#id19" id="id4">5</a> 中找到。</p>
<blockquote>
<div><p>note “Cox Regression (proportional hazards regression)”
可以参见本人的英文博客，其中有对cox回归的介绍以及在R语言中利用cox回归研究实际中的survival analysis。</p>
</div></blockquote>
<blockquote>
<div><p>note “R package”
R 包 <code class="docutils literal notranslate"><span class="pre">superpc</span></code> 实现了监督主成分的算法。</p>
</div></blockquote>
<p>图 18.14 展示了这个例子中有监督的主成分的结果。我们采用 3.53 作为 Cox 得分的分割点，得到了 27 个基因，其中 3.53 是通过 10 折交叉验证得到的。接着我们仅利用这 27 个基因的训练集以及其所对应的测试集中的观测值来计算第一主成分 <span class="math notranslate nohighlight">\((m=1)\)</span>。我们将这些作为 Cox 回归模型的定量变量，其似然比的显著程度为 <span class="math notranslate nohighlight">\(p=0.005\)</span>。当进行二值化（采用训练数据集的均值作为阈值），它能够清晰地将测试集中的病人划分成了低风险和高风险的群体 (图 18.14 中右边中间的图, <span class="math notranslate nohighlight">\(p=0.006\)</span>)。</p>
<p>图 18.14 中右边最上面的图仅仅采用最高得分的基因作为生存的预测变量。在测试集上不显著。同样地，右边最下面的图显示了采用所有训练数据的主成分的二值化，这也是不显著的。</p>
<p>我们的过程允许在第 (2a) 步中采用 <span class="math notranslate nohighlight">\(m &gt; 1\)</span> 个主成分。然而，步骤 (1) 中的有监督使得主成分与输出变量一致，也因此在大部分情形下，只有第一或者前几个主成分对预测有用。在下面的数学部分，我们仅仅考虑第一主成分，但是推广到多余一个主成分可以按照类似的方式进行。</p>
<div class="section" id="id5">
<h2>（）与潜变量模型的联系<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>监督主成分和潜在细胞类型之间的联系可以通过数据的潜变量来体现。假设我们有响应变量 <span class="math notranslate nohighlight">\(Y\)</span>。它通过线性模型与潜变量 <span class="math notranslate nohighlight">\(U\)</span> 关联起来</p>
<div class="math notranslate nohighlight">
\[
Y=\beta_0+\beta_1U+\varepsilon\tag{18.32}
\]</div>
<p>另外，我们有由 <span class="math notranslate nohighlight">\(j\in\mathcal P\)</span> 索引的特征 <span class="math notranslate nohighlight">\(X_j\)</span> 的结合中测量值，其中</p>
<div class="math notranslate nohighlight">
\[
X_j=\alpha_{0j}+\alpha_{1j}U+\epsilon_j\;j\in \mathcal P\tag{18.33}
\]</div>
<p>误差 <span class="math notranslate nohighlight">\(\varepsilon\)</span> 和 <span class="math notranslate nohighlight">\(\epsilon_j\)</span> 假设均值为零且在各自模型中与其它随机变量独立。</p>
<p>我们也有许多额外的特征 <span class="math notranslate nohighlight">\(X_k, k\in \mathcal P\)</span> 是独立于 <span class="math notranslate nohighlight">\(U\)</span> 的。我们想要识别 <span class="math notranslate nohighlight">\(\mathcal P\)</span>，估计 <span class="math notranslate nohighlight">\(U\)</span>，因此拟合预测模型 (18.32)。这是潜变量结构模型的特殊情形，或者说是单组分因子分析模型（Mardia et al., 1979<a class="footnote-reference brackets" href="#id17" id="id6">1</a>，也参见<span class="xref myst">第 14.7 节</span>）潜变量 <span class="math notranslate nohighlight">\(U\)</span>是图 18.13 中概念化的细胞类型的连续版本。</p>
<p>监督主成分算法可以看成是拟合这个模型的方法：</p>
<ol class="simple">
<li><p>第 (1) 步筛查 (screening) 估计集合 <span class="math notranslate nohighlight">\(\mathcal P\)</span>。</p></li>
<li><p>给定 <span class="math notranslate nohighlight">\(\mathcal P\)</span>，用第2(a)步中最大的主成分估计潜变量 <span class="math notranslate nohighlight">\(U\)</span>。</p></li>
<li><p>最后，第 2(b) 中的回归拟合估计模型 (18.32) 中的系数。</p></li>
</ol>
<p>第 (1) 步是自然的，因为平均而言，只有当 <span class="math notranslate nohighlight">\(\alpha_{1j}\)</span> 不为零时，回归系数才是非零的。因此这步应该会选出特征 <span class="math notranslate nohighlight">\(j\in\mathcal P\)</span>。如果我们假设误差 <span class="math notranslate nohighlight">\(\epsilon_j\)</span> 有高斯分布且有相同的方差，则第 (2a) 步也是自然的。这种情形下主成分是单因子模型的极大似然估计 (Mardia et al., 1979<a class="footnote-reference brackets" href="#id20" id="id7">3</a>)。第 (2b) 中的回归是很显然的。</p>
<p>假设总共有 <span class="math notranslate nohighlight">\(p\)</span> 个特征，其中 <span class="math notranslate nohighlight">\(p_1\)</span> 个特征在相关集合 <span class="math notranslate nohighlight">\(\mathcal P\)</span> 中。则如果 <span class="math notranslate nohighlight">\(p\)</span> 和 <span class="math notranslate nohighlight">\(p_1\)</span> 都增长但 <span class="math notranslate nohighlight">\(p_1\)</span> 比 <span class="math notranslate nohighlight">\(p\)</span> 相对较小，可以证明（在合理的条件下）第一主成分对于潜因子是一致的。通常情形下的主成分可能不是一致的，因为它可能被大量的噪声特征所污染。</p>
<p>最后，假设在监督主成分过程中的第 (1) 步使用的阈值产生大量的特征用于计算主成分。则为了解释性，也同样为了实际应用，我们会寻找降维后的子集特征来近似模型。预处理 (Pre-conditioning) 是其中的一种方式。</p>
</div>
<div class="section" id="id8">
<h2>（）与偏最小二乘的联系<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>有监督的主成分与偏最小二乘紧密相关（第 <a class="reference external" href="../03-Linear-Methods-for-Regression/3.5-Methods-Using-Derived-Input-Directions/index.html#_2">3.5.2 节</a>）Bair et al. (2006)<a class="footnote-reference brackets" href="#id19" id="id9">5</a> 发现有监督的主成分效果的关键点在于过滤掉第 2(a) 步中的噪声特征。偏最小二乘减小噪声特征的权重，但不会丢掉它们；结果导致大量的噪声特征会污染预测变量。然而，已经提出的修改版本的偏最小二乘与有监督的主成分有类似的优点（如，Brown et al. (1991)<a class="footnote-reference brackets" href="#id17" id="id10">1</a>, Nadler and Coifman (2005)<a class="footnote-reference brackets" href="#id18" id="id11">2</a>）。我们在监督主成分的第 (1) 步和 (2a) 步选择特征，接着对这些特征应用 PLS （而不是主成分）。对于我们现在的讨论，我们将之称为 “thresholded PLS”。</p>
<p>Thresholded PLS 可以看成是监督主成分的噪声版本，因此我们不会期待它在实际中效果会很好。假设我们的变量全部标准化了，第一 PLS 变量有如下的形式</p>
<div class="math notranslate nohighlight">
\[
\z = \sum_{j\in \mathcal P}\langle y,x_j\ranglex_j\tag{18.34}
\]</div>
<p>并且可以看成对模型 (18.33) 中潜因子 <span class="math notranslate nohighlight">\(U\)</span> 的估计。相反地，监督主成分方向 <span class="math notranslate nohighlight">\(\hat\u\)</span> 满足</p>
<div class="math notranslate nohighlight">
\[
\hat\u = \frac{1}{d^2}\sum\limits_{j\in\mathcal P}\langle \hat\u,x_j\ranglex_j\tag{18.35}
\]</div>
<p>其中 <span class="math notranslate nohighlight">\(d\)</span> 是 <span class="math notranslate nohighlight">\(X_{\mathcal P}\)</span> 第一奇异值。这遵循第一主成分的定义。因此 thresholded PLS 采用 <span class="math notranslate nohighlight">\(y\)</span> 与每个特征的内积作为权重，而有监督的主成分采用特征来导出“self-consistent”的估计量 <span class="math notranslate nohighlight">\(\hat\u\)</span>。因为许多特征都对估计 <span class="math notranslate nohighlight">\(\hat\u\)</span> 起到作用，而不是仅仅是单个输出 <span class="math notranslate nohighlight">\(y\)</span>，我们可以期待 <span class="math notranslate nohighlight">\(\hat\u\)</span> 比 <span class="math notranslate nohighlight">\(\z\)</span> 的噪声更少。事实上，如果在集合 <span class="math notranslate nohighlight">\(\mathcal P\)</span> 中有 <span class="math notranslate nohighlight">\(p_1\)</span> 个特征，且 <span class="math notranslate nohighlight">\(N,p\)</span> 和 <span class="math notranslate nohighlight">\(p_1\)</span> 都趋于无穷，且 <span class="math notranslate nohighlight">\(p_1/N\rightarrow 0\)</span>，则用 Bair et al. (2006)<a class="footnote-reference brackets" href="#id19" id="id12">5</a> 中的技巧可以证明</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\z &amp; = \u +O_p(1)\\
\hat\u &amp;= \u + O_p(\sqrt{p_1/N})
\end{align*}
\tag{18.36}
\end{split}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\u\)</span> 是模型 (18.32) 中真实的（未观测的）潜变量。</p>
<blockquote>
<div><p>note “weiya 注：Big O in Probability”
设 <span class="math notranslate nohighlight">\(X_n\)</span> 为随机变量序列，<span class="math notranslate nohighlight">\(a_n\)</span> 为常值序列，若 <span class="math notranslate nohighlight">\(\forall \varepsilon&gt;0\)</span>，存在 <span class="math notranslate nohighlight">\(M(\varepsilon)\)</span> 和 <span class="math notranslate nohighlight">\(N(\varepsilon)\)</span>，使得当 <span class="math notranslate nohighlight">\(n&gt;N(\varepsilon)\)</span> 时</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[    P\{\vert X_n/a_n\vert &gt; M(\varepsilon)\}&lt;\varepsilon
    
\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>则称 $X_n=O_p(a_n)$。
</pre></div>
</div>
<p>用一个模拟例子来数值比较这些方法。例子中有 <span class="math notranslate nohighlight">\(N=100\)</span> 个样本，<span class="math notranslate nohighlight">\(p=5000\)</span> 个基因。按如下方式生成数据：</p>
<p><img alt="" src="../_images/eq18.37.png" /></p>
<p>其中 <span class="math notranslate nohighlight">\(\epsilon_{ij}\)</span> 和 <span class="math notranslate nohighlight">\(\varepsilon_i\)</span> 是均值为 0 标准差分别为 1 和 1.5 的独立正态随机变量。因此在前 50 个基因中，1-50 号样本与 51-100 号样本有 1 个单位的差异，这个差异与输出 <span class="math notranslate nohighlight">\(y\)</span> 有关。接下来 200 个在样本 (1-25, 51-75) 和样本 (26-50, 76-100) 之间有 4 个单位的平均差异，但是这种差异与输出变量无关。剩下的基因是噪声。图 18.15 展示了经典的热图，其中输出变量在左边，前 500 个基因在右边。</p>
<p>我们从这个模型中产生 100 次模拟，并且在图 18.16 中总结了测试误差的结果。主成分以及偏最小二乘的测试误差展示在图象的右边，两者都受到数据中噪声特征比较大的影响。有监督的主成分和 thresholded PLS 在大部分选择的特征上都表现得很好，且前者有更一致低的测试误差。</p>
<p>尽管这个例子看上去特意为监督主成分设计的，但是它似乎也能在其它模拟和真实数据集中保持良好的表现 (Bair et al., 2006)<a class="footnote-reference brackets" href="#id19" id="id13">5</a>。</p>
</div>
<div class="section" id="id14">
<h2>（）特征选择的预处理<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p>正如图 18.16 展示的，监督主成分可以得到比其它方法更低的测试误差。</p>
<p><img alt="" src="../_images/fig18.16.png" /></p>
<p>然而，并不总是得到只涉及一小部分特征（基因）的稀疏模型。即使算法中的步骤 (1) 的阈值得到相对较少的特征，但可能部分被忽略的特征与监督主成分直接有不可忽略的内积（并且可以看成是较好的代表 (surrogate)）。另外，高相关的特征会趋向于一起选，则在已经选择的特征中会造成较大程度的冗余。</p>
<p>另一方面，lasso（18.4 节和 3.4.2 节）从数据中得到稀疏的模型。应用到上一节中的模拟例子，这两个方法的测试误差会如何呢？图18.17 显示了对于模型 (18.37)，lasso、监督主成分和预处理 lasso（下面描述）的测试误差。</p>
<p><img alt="" src="../_images/fig18.17.png" /></p>
<p>我们看到监督主成分（橘黄色曲线）当大概 50 个特征包含进模型中会达到最低误差，这个数字也是模拟例子中真实的个数。尽管关于前 50 个特征的线性模型是最优的，但是 lasso（绿色）被大量噪声特征所严重影响，而且当模型中有较少的特征时（如图中的 20 个左右）就开始过拟合了。</p>
<p>我们能否得到监督主成分的低测试误差以及 lasso 的稀疏性？这是预处理 (pre-conditioning) 的目标 (Paul et al., 2008<a class="footnote-reference brackets" href="#id21" id="id15">4</a>)。在这种方法中，首先计算训练集中的每个观测的监督主成分的预测量 <span class="math notranslate nohighlight">\(\hat y_i\)</span>（其中阈值通过交叉验证来选择）。接着我们将lasso 应用到 <span class="math notranslate nohighlight">\(\hat y_i\)</span>，其中 <span class="math notranslate nohighlight">\(\hat y_i\)</span> 被看成输出变量，它替换了通常情形下的 <span class="math notranslate nohighlight">\(y_i\)</span>。这个想法是首先对输出变量进行去噪(denoising)，则 lasso 不会被大量噪声特征所影响。图 18.17 显示了预处理（紫色曲线）在这里取得了重要成功，比通常的 lasso的测试误差要低很多，在这种情形下与监督主成分一样第。而且采用更少的特征便达到了最小测试误差。应用到原始输出变量的一般 lasso 比预处理 lasso 更快地过拟合。预处理 lasso 的过拟合不是问题，因为输出变量已经去噪了。对于预处理的 lasso，我们经常用更主管的理由来选择调整参数，比如简约性(parsimony)。</p>
<p>预处理可以应用到不同的设定中，采用除监督主成分外的初始估计和除 lasso 以外的后续估计。更多细节可以在 Paul et al. (2008)<a class="footnote-reference brackets" href="#id21" id="id16">4</a> 中找到。</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id17"><span class="brackets">1</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id6">2</a>,<a href="#id10">3</a>)</span></dt>
<dd><p>Rosenwald, A., Wright, G., Chan, W. C., Connors, J. M., Campo, E., Fisher, R. I., Gascoyne, R. D., Muller-Hermelink, H. K., Smeland, E. B. and Staudt, L. M. (2002).  The use of molecular profiling to predict survival after chemotherapy for diffuse large b-cell lymphoma, The New England Journal of Medicine 346: 1937–1947</p>
</dd>
<dt class="label" id="id18"><span class="brackets">2</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id11">2</a>)</span></dt>
<dd><p>Kalbfleisch, J. and Prentice, R. (1980). The Statistical Analysis of Failure Time Data, Wiley, New York.</p>
</dd>
<dt class="label" id="id19"><span class="brackets">5</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id9">2</a>,<a href="#id12">3</a>,<a href="#id13">4</a>)</span></dt>
<dd><p>Bair, E., Hastie, T., Paul, D. and Tibshirani, R. (2006). Prediction by supervised principal components, Journal of the American Statistical Association 101: 119–137.</p>
</dd>
<dt class="label" id="id20"><span class="brackets"><a class="fn-backref" href="#id7">3</a></span></dt>
<dd><p>Mardia, K., Kent, J. and Bibby, J. (1979). Multivariate Analysis, Academic Press.</p>
</dd>
<dt class="label" id="id21"><span class="brackets">4</span><span class="fn-backref">(<a href="#id15">1</a>,<a href="#id16">2</a>)</span></dt>
<dd><p>Paul, D., Bair, E., Hastie, T. and Tibshirani, R. (2008). “Pre-conditioning” for feature selection and regression in high-dimensional problems, Annals of Statistics 36(4): 1595–1618. <span class="xref myst">下载</span></p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./18-High-Dimensional-Problems"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="18.5-Classification-When-Features-are-Unavailable.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">18.5 当特征不可用时的分类</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="18.7-Feature-Assessment-and-the-Multiple-Testing-Problem.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">18.7 特征评估和多重检验问题</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Trevor Hastie and Robert Tibshirani and Jerome Friedman<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>