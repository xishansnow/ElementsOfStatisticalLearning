# 7.4 训练误差率的乐观估计

<style>p{text-indent:2em;2}</style>

讨论误差率估计的问题可能令人困惑，因为必须弄清楚哪些量是固定的、哪些量是随机的。在我们继续之前，需要做一些定义，详细阐述第 7.2 节的内容。

给出训练集 $\mathcal{T} =\{(x_1,y_1),(x_2,y_2),\ldots,(x_N,y_N)\}$，模型 $\hat f$ 的泛化误差为：

$$
\mathbb{Err}_{\mathcal{T} } = \mathrm E_{X^0,Y^0}[L(Y^0,\hat f(X^0))\mid {\mathcal{T} }]\tag{7.15} 
$$

注意：在式（ 7.15 ） 中训练集 $\mathcal{T}$ 是固定的。点 $(X^0,Y^0)$ 是新的测试点，从数据的联合分布 $F$ 中取的。对数据集平均可以得到误差的期望 (expected error)：

$$
\mathrm{Err} = \mathrm E_{\mathcal{T} }\mathrm E_{X^0,Y^0}[L(Y^0,\hat f(X^0))\mid {\mathcal{T} }]\tag{7.16} 
$$

它更适合于统计分析。正如之前提到的，事实证明大部分方法能够有效估计误差的期望，而非 $\mathbb{Err}_{\mathcal{T} }$；这一点详见 7.12 节。

现在一般地，训练误差 (training error) 为：

$$
\overline{\mathbb{err}} = \frac{1}{N}\sum\limits_{i=1}^NL(y_i,\hat f(x_i))\tag{7.17} 
$$

训练误差通常会比泛化误差 $\mathbb{Err}\_{\mathcal{T} }$ 小，因为数据被同时用于拟合学习方法并且评估误差（见 练习 2.9）。拟合方法一般适应于训练数据，因此表面误差 (apparent error)或训练误差 $\overline{\mathbb{err}}$ 是对泛化误差 $\mathbb{Err}_{\mathcal{T}}$ 过度乐观的估计。

这种差异部分是因为取值点的选取造成的。值 $\mathbb{Err}_{\mathcal{T} }$ 可以看成是样本外误差 (extra-sample error)，因为测试的输入向量不需要与训练的输入向量一致。当我们观察样本内误差 (in-sample error)时，就可以很简单地理解 $\overline{\mathbb{err}}$ 做出乐观估计的本质。

$$
\mathbb{Err}_{in}=\frac{1}{N}\sum_{i=1}^N\mathrm E_{Y^0}[L(Y_i^0,\hat f(x_i))\mid {\mathcal{T} }]\tag{7.18}
$$

$Y^0$ 表示我们在每个训练点 $x_i,i=1,2,\ldots,N$ 处观测 $N$ 个新响应变量的值。我们定义 $\mathbb{Err}_{in}$ 与训练误差 $\overline{\mathbb{err}}$ 的差为乐观值 (optimism)：

$$
\mathrm {op}\equiv \mathrm{Err}_{in}-\overline{\mathbb{err}}\tag{7.19} 
$$

一般情形下这是正的，因为 $\overline{\mathbb{err}}$ 经常是预测误差的向下有偏估计。最终，平均乐观是乐观值在训练集上的期望：

$$
\omega \equiv E_{\mathbf y}(\mathrm{op})\tag{7.20} 
$$

这里训练集中的预测变量是固定的，期望是对训练集的输出值而言的；因此我们已经用记号 $\mathbb{E}_{\mathbf{y}}$ 而不是 $\mathbb{E}_{\mathcal{T} }$。我们通常仅仅估计期望误差 $\omega$ 而不是 op，就像我们可以估计期望误差 $\mathbb{Err}$ 而不是条件误差 $\mathbb{Err}_{\mathcal{T} }$。

对于`平方误差损失`、`0-1 损失`以及其他损失函数，可以证明一般性的结论：

$$
\omega=\frac{2}{N}\sum\limits_{i=1}^N\mathbb{Cov}(\hat y_i,y_i)\tag{7.21} 
$$

其中 $\mathbb{Cov}$ 表示协方差。因此 $\overline{\mathbb{err}}$ 低估真实误差的程度取决于 $y_i$ 影响它本身估计的程度。数据越难拟合，$\mathbb{Cov}(\hat y_i,y_i)$ 将越大，因此增大了乐观。练习 7.4 证明了平方损失函数时的结果，其中 $\hat y_i$ 为根据回归拟合好的值。对于 0-1 损失，$\hat y_i\in\\{0,1\\}$ 是在 $x_i$ 处的分类，另外对于熵损失，$\hat y_i\in[0,1]$ 是在 $x_i$ 处类别 1 的拟合概率。

总结一下，我们有重要的关系式：

$$
\mathbb{E}_{\mathbf y}(\mathbb{Err}_{in})=\mathbb{E}_{\mathbf y}(\overline{\mathbb{err}})+\frac{2}{N}\sum\limits_{i=1}^N\mathbb{Cov}(\hat y_i,y_i)\tag{7.22}\label{7.22}
$$

如果 $\hat y_i$ 通过含 $d$ 个输入或者基函数的线性拟合得到，上面表达式可以简化。例如，对于可加误差模型 $Y=f(X)+\varepsilon$，

$$
\sum\limits_{i=1}^N\mathbb{Cov}(\hat y_i,y_i) = d\sigma_{\varepsilon}^2\tag{7.23}\label{7.23}
$$

因此

$$
\mathbb{E}_{\mathbf y}(\mathbb{Err}_{in})=\mathbb{E}_{\mathbf y}(\overline{\mathbb{err}})+2\cdot\frac{d}{N}\sigma_\varepsilon^2\tag{7.24} 
$$
 
表达式（ 7.23 ） 是定义 `有效参数个数 (effective number of parameters)` （将在 7.6 节讨论）的基础。乐观值随着我们使用的输入或基函数的个数 $d$ 线性增长，但是当训练样本大小增大时会降低。式（7.24）的其它版本对其它误差模型也近似成立，比如二值数据和熵损失。

估计预测误差的一种明显方法是先估计乐观值，然后加到训练误差 $\overline{\mathbb{err}}$ 上。下一节将要描述的方法（关于参数的线性估计类），如： $C_p$，`AIC`，`BIC` 以及其它方法，都是通过该方式实现的。

相反地，本章后面描述的交叉验证以及自助法是对样本外（ extra-sample ）误差 $\mathbb{Err}$ 直接估计的方法。此类工具可以用于任意损失函数以及非线性拟合。

样本内误差通常不是直接感兴趣的，因为特征的未来值不可能与其训练值一致。但是为了模型之间的比较，样本内误差是很方便的，并且经常能够有效地进行模型选择。原因在于误差的相对而不是绝对大小才是我们真正关心的。
