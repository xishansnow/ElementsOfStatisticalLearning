# 2.2 变量类型和术语

<style>p{text-indent:2em;2}</style>

**（1）主要变量类型**

前文的例子中，输出变量本质存在一些不同。

- 在预测葡萄糖的例子中，输出变量是 **定量 (quantitative)** 的度量，度量有大小，而且结果在数值上相近也意味着结果本质上相近。

- 在鸢尾花种类的例子中，输出变量（鸢尾花的种类）是 **定性的 (qualitative)** ，取值范围是有限集合 $\mathbb{G}= \{ \text{Virginica},\text{Setosa},\text{Versicolor} \}$ 。在手写数字的例子中，输出变量的取值是 $10$ 个不同数字之一。 $\mathcal {G}=\{0,1,...,9\}$ 。这两个例子中分类没有明显顺序，而且事实上经常用描述性标签而不是数值来代替这些分类。定性变量也被称为 **类别型 ( categories )** 或者 **离散型 ( discrete )** 变量，也被称作 **因子 ( factors )**。

对于“定量”和“定性”两种类型的输出变量，考虑使用输入变量去预测输出是有意义的。前者如“给定今天和昨天的大气测量结果，想要预测明天的臭氧层？” ；后者如 “给定手写数字的数字化图片中像素的灰度值，想要预测该图片属于哪一类？”。

输出类型的差别导致对预测的命名规定：当预测定量的输出时被称为 **回归 ( regression )**，当预测定性的输出时被称为 **分类 ( classification )** 。我们将会看到这两类任务有很多共同点，特别是，两者都可以看成是函数逼近。

输入变量也有各种各样的类型。可以有定性的输入变量，也可以有定量的输入变量。这些也导致了预测中方法类型的不同：有些方法定义为定量的输入变量，有些方法定义为定性的输入变量，还有一些方法两种输入都存在。

第三种变量类型是 **定序分类 (ordered categorical)**，如 小 (small )、中 (medium) 和 大 (large) 。这些值之间存在顺序，但没有合适的度量概念（ 中与小之间的差异不必和大与中间的差异相等 ）。这将在 [第四章](../04-Linear-Methods-for-Classification/4.1-Introduction/index.html) 中讨论。

定性变量经常采用数字编码的方式表示。最简单的情形是只有两个分类，比如说“成功”与“失败”，“生存”与“死亡”。这些经常用一个 $bit$ 的二进制数来表示，比如 $0$ 和 $1$，或者 $-1$ 和 $1$ 。因为一些比较明显的原因，这些数字编码有时也被称作 **指示变量**。

当存在超过两个类别时，最普遍使用的编码之一就是 **虚拟变量 (dummy variables) 或 独热变量（One-hot）**。即用 $K$ 个 $bit$ 的一个二进制数来表示类别，不同类别对应其中某一个 $bit$ ，每次只有一个 $bit$ 处于开启状态，其他 $bit$ 均为 $0$。

**（2）默认符号表示法**

在机器学习领域，对于输入和输出变量通常有一些约定俗称的表示方法：

- 用符号 $X$ 表示输入变量。如果 $X$ 是一个向量，则其组份可以用下标 $X_j$ 取出。

- 用符号 $Y$ 表示定量的输出变量。

- 用符号 $G$ 来表示定性的输出变量。

- 用`大写字母` $X,Y,G$ 泛指某个变量；如果该变量是一个向量，则可以用下标来区分其分量，如 $X_i$ 泛指变量 $X$ 的第 $i$ 个分量。

- 用`小写字母` $x,y,g$ 表示某个变量的实例；因此变量 $X$ 的第 $i$ 个实例应记作 $x_i$ （$x_i$ 为标量或向量）。

- 当向量具有 $N$ 个组成部分时，才用`粗体小写字母` $\mathbf{x}$ 来表示。例如，第 $j$ 个输入变量 $X_j$ 的所有观测值构成的 $N$ 维向量，可以表示为 $\mathbf{x}_j$ 。此约定主要用于和上一条当中变量 $X$  （ 为 $p$ 维向量时）的第 $i$ 个观测值 $x_i$ 做区分，两者均为向量，但含义有显著区别。另外，本书中的所有向量均为列向量。

- 用`粗体大写字母` $\mathbf{X}$ 来表示矩阵。例如，$N$ 个 $p$ 维输入向量 $x_i,\{i=1 \ ,\cdots,N\}$ 可以用一个大小为 $N\times p$ 的矩阵 $\mathbf{X}$ 来表示。因为所有向量均假定为列向量，所以 $\mathbf{X}$ 的第 $i$ 行是向量 $x_i$ 的转置 $x_i^T$ 。

**（3）问题的符号化叙述**

现在我们可以不严谨地把学习叙述成为：给定输入向变量 $X$，对输出 $Y$ 做出一个很好的估计，记为 $\hat{Y}$ 。如果 $Y$ 取值范围为 $\mathbb{R}$，则 $\hat{Y}$ 取值范围也是 $\mathbb{R}$ ；同样地，对于类别型输出，$\hat{G}$ 取值为对应 $G$ 取值的集合 $\mathbb{G}$。

对于只有两种类别的 $G$，一种方式是把二进制编码记为 $Y$，然后把它看成是定量的输出。预测值 $\hat{Y}$ 一般落在 $[0,1]$ 之间，而且我们可以根据是否 $\hat{y} > 0.5$ 来给 $\hat{G}$ 赋值。此方式可以泛化到有 $K$ 个类别的定性输出。

我们需要数据去构建预测规则，经常是大量的数据。因此假设有一系列可用的测量值 $(x_i,y_i)$ 或 $(x_i,g_i), \{i=1,\cdots,N\}$ ，这被称之为 **训练数据 (training data)**。我们将利用这些训练数据构建预测规则。
