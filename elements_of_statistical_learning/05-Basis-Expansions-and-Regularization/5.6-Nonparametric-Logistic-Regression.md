# 5.6 非参逻辑斯蒂回归

<style>p{text-indent:2em;2}</style>

[5.4 节](../5.4-Smoothing-Splines/index.html)的平滑样条问题 (5.9) 是在回归的背景下提出来的。可以非常直接地将其推广到其他领域。这里我们考虑单个定量输入变量 $X$ 的逻辑斯蒂回归。模型为


$$
\log\frac{\mathrm{Pr}(Y=1\mid X=x)}{\mathrm{Pr}(Y=0\mid X=x)}=f(x)\tag{5.28}
$$

这表明


$$
\mathrm{Pr}(Y=1\mid X=x)=\frac{e^{f(x)}}{1+e^{f(x)}}\tag{5.29}
$$

以平滑化的方式对 $f(x)$ 进行拟合会得到条件概率 $\mathrm{Pr}(Y=1\mid x)$ 的平滑估计，它可以用来分类或者风险评分。

我们构造如下的带惩罚的对数似然准则


$$
\begin{align*}
\ell(f;\lambda)&=\sum\limits_{i=1}^N[y_i\log p(x_i)+(1-y_i)\mathrm{log}(1-p(x_i))]-\frac{1}{2}\lambda\int \{f''(t)\}^2dt\\
&=\sum\limits_{i=1}^N[y_if(x_i)-\log(1+e^{f(x_i)})]-\frac{1}{2}\lambda \int\{f''(t)\}^2dt\tag{5.30}
\end{align*}
$$

其中 $p(x)=\mathrm{Pr}(Y=1\mid x)$。上述表达式的第一项为基于二项分布的对数似然。在 [5.4 节](../5.4-Smoothing-Splines/index.html)中使用的类似的参数证明了最优的 $f$ 是连接点在无重复的 $x$ 处的有限维自然样条。这意味着我们可以表示成 $f(x)=\sum_{j=1}^NN_j(x)\theta_j$。我们比较一阶微分和二阶微分


$$
\frac{\partial \ell(\theta)}{\partial \theta}=\mathbf {N^T(y-p)-\lambda\Omega}\theta\tag{5.31}
$$

$$
\frac{\partial^2\ell(\theta)}{\partial\theta\partial\theta^T}=-\mathbf{N^TWN-\lambda \Omega}\tag{5.32}
$$

其中 $\mathbf p$ 是元素为 $p(x_i)$ 的 $N$ 维向量，$\mathbf W$ 是权重为 $p(x_i)(1-p(x_i)$ 的对角矩阵。(5.31) 的一阶微分关于 $\theta$ 是非线性的，所以我们需要运用和 [4.4.1 节](../04-Linear-Methods-for-Classification/4.4-Logistic-Regression/index.html)一样的迭代算法。采用类似用于线性逻辑斯蒂回归的 (4.23) 和 (4.26) 的 Newton-Raphson 算法，更新的等式可以写成

$$
\begin{align*}
\theta^{new} &=\mathbf{(N^TWN+\lambda\Omega)^{-1}N^TW(N\theta^{old}+W^{-1}(y-p))}\\
&= \mathbf{(N^TWN+\lambda\Omega)^{-1}N^TWz}\tag{5.33}
\end{align*}
$$

也可以用拟合值表示更新


$$
\begin{array}{ll}
\mathbf f^{new} &=\mathbf{N(N^TWN+\lambda\Omega)^{-1}N^TW(f^{old}+W^{-1}(y-p))}\\
&= \mathbf{S_{\lambda,w}z}\tag{5.34}
\end{array}
$$

参考 (5.12) 和 (5.14) 式，

我们看到更新的操作对**工作响应变量 (working response)** $\mathbf z$ 拟合了加权平滑样条（[练习 5.12](https://github.com/szcf-weiya/ESL-CN/issues/107)）。

式 (5.34) 的形式很有指导意义。它试图用任何非参（加权）回归算子代替 $\mathbf S_{\lambda,w}$，并且得到一般的非参逻辑斯蒂回归模型的族。尽管这里 $x$ 是一维的，但这个过程可以很自然地推广到高维的 $x$。这些拓展是 **广义可加模型 (generalized additive models)** 的核心，我们将在[第 9 章](../09-Additive-Models-Trees-and-Related-Methods/9.0-Introduction/index.html)中讨论。
