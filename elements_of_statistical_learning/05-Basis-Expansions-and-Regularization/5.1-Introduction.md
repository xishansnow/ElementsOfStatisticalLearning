# 5.1 导言

<style>p{text-indent:2em;2}</style>

我们已经对回归和分类任务使用了关于预测变量的线性模型。线性回归、线性判别分析、逻辑斯蒂回归和分离超平面都依赖于线性模型。

但是，关于 $X$ 的真实的函数 $f(X)$ 不太可能恰好是线性的。在回归问题中，$f(X)=\mathbb{E}(Y\mid X)$ 关于 $X$ 一般情况下都不是线性的，可能也不是可加的，不过用线性模型作为一种近似来表示 $f(X)$ ，通常又是方便和必要（有时候）的。方便是因为线性模型很容易解释，而且 $f(X)$ 可被视为任意可微函数的一阶泰勒近似。有时候必要是因为当 $N$ 很小而 $p$ 很大时，线性模型相对于其他参数模型而言，使用的参数更少，不需要过拟合就可以达到拟合数据的目的。在分类任务中也类似，一个线性的、贝叶斯最优的判别边界表明 $\mathrm{Pr}(Y=1\mid X)$ 的某些单调变换关于 $X$ 是线性的，无疑这种线性判别边界也是一种近似。

本章和接下来各章节中，我们将讨论一些不同于或超越线性模型的流行方法。本章核心是用额外的变量来增强（或替换）输入向量 $X$ ，然后在新变量的输入特征空间中运用线性模型。

用 $h_m(X):\mathbb{R}^p\longmapsto \mathbb{R}$ 表示 $X$ 的第 $m$ 个变换（ 基函数 ），$m=1,\ldots, M$ 。然后可以将下式建模为 $X$ 的一个`线性基展开（Linear Basis Expansion）`：

$$
f(X)=\sum\limits_{m=1}^M\beta_mh_m(X)\tag{5.1}
$$

线性基展开式的优雅之处在于：只要基函数 $h_m$ 确定了，模型关于这些基函数产生的新变量整体上就是线性的，可以像前两章一样进行线性地拟合。

下面给出了一些简单、常见的基函数：

- $h_m(X)=X_m,m=1,\ldots,p$ 

这其实就是原始输入向量，只是换了一种表达形式。

- $h_m(X)=X_j^2$ 或 $h_m(X)=X_jX_k$ 

这是对原始输入的二阶多项式项，与一阶多项式结合可以达到高阶泰勒展开的目的。注意：转化后变量的个数以多项式程度快速增长，含 $p$ 个变量的二次模型要求 $O(p^2)$ 的平方项和交互项；或者更一般地，对于阶数为 $d$ 的多项式需要 $O(p^d)$ 个变量。

- $h_m(X)=\log(X_j) \  或  \ \sqrt{X_j} $ 等

这是对原始输入中单变量的非线性变换。更一般性地，可以使用包含原始输入中多个变量构成的类似函数，比如说  $h_m(X)=\Vert X\Vert$ 。

- $h_m(X)=I(L_m\le X_k\le U_m)$

关于 $X_k$ 区域的指示性函数。如果将 $X_k$ 分成 $M_k$ 个非重叠的区间，每个区间具有一个不同的指示值，则结果可以得到一个关于 $X_k$ 的分段常数模型。

有时候，手边的问题要求我们必须采用特定类型的基函数，比如对数函数或者幂函数；但更多情况下，我们做基展开的目的，就是用于增加 $f(X)$ 的灵活性。典型如多项式回归。不过多项式回归最大的问题在于，其多次项是面向整个输入空间的，局部的灵活性，往往会给全局带来扰动。

为此，本章中会考虑比多项式回归更实用的 **分段多项式** 和 **样条** 。这两种基展开方法允许函数的局部多项式表示，从而规避了全局扰动。我们还会考虑小波基，这在信号和图像处理任务中特别有用。上述三种方法都会产生一个包含 $\vert\mathcal D\vert$ 个基函数的字典 $\mathcal D$ ，并且  $\vert\mathcal D\vert$  有可能远远超出参与拟合的数据量 $N$。

除了字典 $\mathcal D$ 外，我们还需要一种方式从基函数字典中合理地选择基函数（ 或者控制模型的复杂度 ）。通常有三种方式：

**（ 1 ）限制方法**，事先确定和限制基函数的类别（可理解为一种静态模型）。例如，可加性就是一个例子，假设模型有如下形式：
  
$$
\begin{align*}
  f(X)&=\sum\limits_{j=1}^pf_j(X_j)\\
  &=\sum\limits_{j=1}^p\sum\limits_{m=1}^{M_j}\beta_{jm}h_{jm}(X_j)\tag{5.2}
\end{align*}  
$$

  则该模型的大小（复杂度）由 $p$ 个加性函数组份 $f_j(X_j)$ 中的基函数个数 $M_j$ 决定。

**（ 2 ）选择方法**，自适应地扫描词典 $\mathcal D$ ，保留其中对模型拟合有显著性作用的基函数 $h_m$ ，可理解为一种自适应调整基函数选择的动态模型。第三章中讨论的变量选择技巧是很有用的。另外，类似 `CART`，`MARS` 和 `boosting` 等逐步贪婪方法也可以划为这一类。

**（ 3 ）正则化方法**，使用整个字典，但是对系数作出某种约束，可理解为一种自适应调整基函数系数的动态模型。`岭回归`是一种比较简单的正则化例子；`套索（ Lasso ）` 则既属于正则化方法，也属于选择方法。

本章将讨论上述内容，以及更加复杂的正则化方法。
