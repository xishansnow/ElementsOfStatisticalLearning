# 5.1 导言

<style>p{text-indent:2em;2}</style>

我们已经对回归和分类运用了关于输入特征为线性的模型。线性回归，线性判别分析，逻辑斯蒂回归和分离超平面都依赖于线性模型。关于 $X$ 的真实的函数 $f(X)$ 不太可能恰好为线性的。在回归问题中，$f(X)=\mathbb{E}(Y\mid X)$ 关于 $X$ 一般不是线性的，也不是可加的，但用线性模型来表示 $f(X)$ 通常是方便的、有时候是必要的近似。方便是因为线性模型是可以很容易地解释，而且 $f(X)$ 可被视为任意复杂函数的一阶泰勒近似。有时候必要是因为当 $N$ 很小 $p$ 很大时，线性模型由于参数少，因而可以不需要过拟合就达到拟合数据的目的。在分类任务中也类似，一个线性的、贝叶斯最优的判别边界表明 $\mathrm{Pr}(Y=1\mid X)$ 的某些单调变换关于 $X$ 也是线性的，无疑这也是一种近似。

本章和接下来各章节中，我们将讨论一些不同于或超越线性模型的流行方法。本章核心是用额外的变量来增强（或替换）输入向量 $X$ ，然后在新变量的输入特征空间中运用线性模型。

用 $h_m(X):\mathbb{R}^p\longmapsto \mathbb{R}$ 表示 $X$ 的第 $m$ 个变换（ 基函数 ），$m=1,\ldots, M$ 。然后可以将下式建模为 $X$ 的一个`线性基展开（Linear Basis Expansion）`：

$$
f(X)=\sum\limits_{m=1}^M\beta_mh_m(X)\tag{5.1}
$$

线性基展开式的优雅之处在于：只要基函数 $h_m$ 被确定了，则模型关于这些基函数产生的新变量整体上是线性的，继而可以像前两章一样进行线性地拟合。

下面给出了一些简单、常用的 $h_m$ ：

- $h_m(X)=X_m,m=1,\ldots,p$ 

这其实就是原来的输入向量，只是换了一种表达形式。

- $h_m(X)=X_j^2$ 或者 $h_m(X)=X_jX_k$ 

增加输入中的多项式项来达到高阶泰勒展开的目的。注意到变量的个数以多项式程度呈指数增长；含 $p$ 个变量的二次模型要求 $O(p^2)$ 的平方项和交叉项；或者更一般地，对于阶数为 $d$ 的多项式需要 $O(p^d)$ 个变量

- $h_m(x)=\log(X_j),\sqrt{X_j},\ldots$ 

允许单输入的其它非线性变换。更一般地，可以使用含有其他输入变量的类似函数，比如说  $h_m(X)=\Vert X\Vert$ 。

- $h_m(X)=I(L_m\le X_k\le U_m)$

关于 $X_k$ 区域的指示性函数。将 $X_k$ 的值域分成 $M_k$ 个非重叠区域，结果得到一个关于 $X_k$ 分段常数的分布模型。

有时候，手边的问题要求我们采用特殊的基函数 $h_m$，比如对数或者幂函数；但更多情况下，我们希望通过基展开来增加 $f(X)$ 的灵活性。多项式回归就是后者的一个典型例子，尽管受到全局性质的限制（ 多项式回归在调整系数以实现某区域函数形式时，可能会导致在其他区域的疯狂扰动 ）。

本章中，我们会考虑可能比多项式回归更实用的 **分段多项式 (piecewise-polynimials)** 族和 **样条 (splines)** ，这两种方法允许局部多项式表示，从而规避的全局扰动。我们还会考虑小波基，这在信号和图像处理任务中特别有用。这几类方法都会产生包含 $\vert\mathcal D\vert$ 个基函数的基函数字典 $\mathcal D$ ，其数量有可能远远超出能够参与拟合的数据。

除了字典 $\mathcal D$ 外，我们还需要一种方式来控制模型的复杂度（ 如从基函数字典中合理地选择基函数 ）。通常有三种方式：

**（ 1 ）限制方法**，事先确定限制基函数的类别。例如，可加性就是一个例子，假设模型有如下形式：
  
$$
\begin{align*}
  f(X)&=\sum\limits_{j=1}^pf_j(X_j)\\
  &=\sum\limits_{j=1}^p\sum\limits_{m=1}^{M_j}\beta_{jm}h_{jm}(X_j)\tag{5.2}
\end{align*}  
$$

  则该模型的大小（复杂度）由 $p$ 个加性组份函数 $f_j$ 中的基函数个数 $M_j$ 决定。

**（ 2 ）选择方法**，自适应地扫描词典 $\mathcal D$ 并保留对模型拟合有显著性作用的基函数 $h_m$ 。第三章中讨论的变量选择技巧是很有用的。另外，类似 `CART`，`MARS` 和 `boosting` 等逐步贪婪方法可以划为这一类。

**（ 3 ）正则化方法**，使用整个字典，但是对系数作出某种约束。`岭回归`是一种比较简单的正则化例子；`套索（ Lasso ）` 则既属于正则化方法，也属于选择方法。

本章将讨论上述内容，以及更加复杂的正则化方法。
